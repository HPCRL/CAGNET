#!/bin/bash
#BSUB -P BIF115
#BSUB -W 2:00
#BSUB -nnodes 21
#BSUB -alloc_flags gpumps
#BSUB -J distr-gnn2d-p121
#BSUB -o distr-gnn.%J
#BSUB -e distr-gnn.%J

conda activate gnn2

module load cuda
module load gcc

module list

# hostarr=(${LSB_HOSTS})
# echo $LSB_MCPU_HOSTS
hostarr=(${LSB_MCPU_HOSTS})
echo ${hostarr[2]}

# declare -a midlayers=("16" "64" "256")
declare -a midlayers=("64")
declare -a timings=("True" "False")

cd ../../

# # Reddit
# for i in "${midlayers[@]}"
#     do
#         for j in "${timings[@]}"
#             do
#                 ddlrun -x WORLD_SIZE=121 -x MASTER_ADDR=${hostarr[2]} -x MASTER_PORT=1234 -accelerators 6 python gcn_distr_2d_gpu_floor.py --accperrank=6 --epochs=40 --graphname=Reddit --timing=$j --midlayer=$i &> outputs/final_outputs/packed/reddit/distr_proc121_2d_output_mid$i\_$j\_nomemleak.txt
# 
#             done
#     done

# Amazon
for i in "${midlayers[@]}"
    do
        for j in "${timings[@]}"
            do
                # ddlrun -x WORLD_SIZE=100 -x MASTER_ADDR=${hostarr[2]} -x MASTER_PORT=1234 -accelerators 4 python gcn_distr_2d_gpu.py --accperrank=4 --epochs=30 --graphname=Amazon --timing=$j --midlayer=$i &> outputs/final_outputs/amazon/distr_proc100_2d_output_mid$i\_$j\.txt
                ddlrun -x WORLD_SIZE=121 -x MASTER_ADDR=${hostarr[2]} -x MASTER_PORT=1234 -accelerators 6 python gcn_distr_2d_gpu_floor.py --accperrank=6 --epochs=40 --graphname=Amazon --timing=$j --midlayer=$i &> outputs/final_outputs/random/amazon/distr_proc121_2d_output_mid$i\_$j\_nomemleak.txt

            done
    done

# # subgraph3
# for i in "${midlayers[@]}"
#     do
#         for j in "${timings[@]}"
#             do
#                 ddlrun -x WORLD_SIZE=121 -x MASTER_ADDR=${hostarr[2]} -x MASTER_PORT=1234 -accelerators 6 python gcn_distr_2d_gpu_floor.py --accperrank=6 --epochs=10 --graphname=subgraph3 --timing=$j --midlayer=$i &> outputs/final_outputs/packed/subgraph3/distr_proc121_2d_output_mid$i\_$j\_nomemleak.txt
# 
#             done
#     done
